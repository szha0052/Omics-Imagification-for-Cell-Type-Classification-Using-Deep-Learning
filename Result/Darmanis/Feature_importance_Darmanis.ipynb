{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e3b76150",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"\n",
    "\n",
    "import torch\n",
    "torch.use_deterministic_algorithms(True)\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "import tensorflow as tf\n",
    "\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.use_deterministic_algorithms(True)\n",
    "\n",
    "\n",
    "\n",
    "from model.Vec2Image_py.get_matrix import get_matrix\n",
    "from model.Vec2Image_py.trainer import get_net_trainer\n",
    "from model.Vec2Image_py.getNETtest import NetTester\n",
    "from model.Vec2Image_py.getSMOTE import SmoteGenerator\n",
    "from model.Vec2Image_py.getPrioritizeGene import getPrioritizeGene\n",
    "from model.Vec2Image_py.Cart2Pixel import Cart2Pixel\n",
    "from model.Vec2Image_py.ConvPixel import ConvPixel\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06c35e1",
   "metadata": {},
   "source": [
    "# 1. Vec2Image_data_processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e7da5d1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def Vec2Image_data_processing(filepath, Parm):\n",
    "    print(\"\\nLoading full gene expression dataset...\")\n",
    "    df = pd.read_csv(filepath)\n",
    "    set_seed(42)\n",
    "\n",
    "    X_full = df.iloc[:, 1:].to_numpy(dtype=np.float32)\n",
    "    labels_full = [col.split('.')[0] for col in df.columns[1:]]\n",
    "    label_map = {label: idx for idx, label in enumerate(sorted(set(labels_full)))}\n",
    "    y_full = np.array([label_map[l] for l in labels_full])\n",
    "    num_classes = len(label_map)\n",
    "\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(\"\\nLabel to index mapping:\")\n",
    "    for label, idx in label_map.items():\n",
    "        print(f\"  {label}: {idx}\")\n",
    "\n",
    "\n",
    "    dset = {\n",
    "        'Xtrain': X_full,\n",
    "        'train_labels': y_full.astype(int),\n",
    "    }\n",
    "    print(\"\\nRunning get_matrix...\")\n",
    "    Out = get_matrix(dset, Parm)\n",
    "\n",
    "    print(\"\\nApplying SMOTE...\")\n",
    "    smote = SmoteGenerator(dset['Xtrain'].T, dset['train_labels'], seed=42)\n",
    "    X_aug, y_aug = smote.fit_resample()\n",
    "    X_aug = X_aug.T\n",
    "\n",
    "    print(\"\\nTesting ConvPixel...\")\n",
    "    sample_vec = dset['Xtrain'][:, 0]\n",
    "    image = ConvPixel(sample_vec, dset['xp'], dset['yp'], dset['A'], dset['B'], dset['Base'])\n",
    "    print(\"Image shape:\", image.shape)\n",
    "\n",
    "    print(\"\\nEncoding labels...\")\n",
    "    le = LabelEncoder()\n",
    "    y_aug_int = le.fit_transform(y_aug)\n",
    "    y_val_int = le.transform(dset['Validation_labels'])\n",
    "\n",
    "    y_train_oh = np.eye(len(le.classes_))[y_aug_int]\n",
    "    y_val_oh = np.eye(len(le.classes_))[y_val_int]\n",
    "    dset['label_encoder'] = le\n",
    "\n",
    "\n",
    "    print(\"\\nConverting augmented data to images...\")\n",
    "    X_train_imgs = np.zeros((X_aug.shape[1], 1, dset['A'], dset['B']), dtype=np.float32)\n",
    "    for i in range(X_aug.shape[1]):\n",
    "        fvec = X_aug[:, i][Out['feature_order']] \n",
    "        X_train_imgs[i, 0, :, :] = ConvPixel(fvec, dset['xp'], dset['yp'], dset['A'], dset['B'], dset['Base'], 0)\n",
    "\n",
    "\n",
    "    print(\"\\nPreparing validation images...\")\n",
    "    X_val_imgs = dset['XValidation'].transpose(3, 2, 0, 1)\n",
    "\n",
    "    print(\"\\nFinished dataset preparation.\")\n",
    "    return {\n",
    "        'X_train_imgs': X_train_imgs,\n",
    "        'X_val_imgs': X_val_imgs,\n",
    "        'y_train_oh': y_train_oh,\n",
    "        'y_val_oh': y_val_oh,\n",
    "        'label_map': label_map,\n",
    "        'num_classes': num_classes,\n",
    "        'original_dataset': dset,\n",
    "        'Out': Out,\n",
    "        'dset': dset\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03019db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Parm = {\n",
    "    'Method': 'tSNE',\n",
    "    'Max_Px_Size': 30,\n",
    "    'MPS_Fix': 1,\n",
    "    'ValidRatio': 0.2,\n",
    "    'Seed': 42,\n",
    "    'NORM': 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e844c92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading full gene expression dataset...\n",
      "Number of classes: 9\n",
      "\n",
      "Label to index mapping:\n",
      "  OPC: 0\n",
      "  astrocytes: 1\n",
      "  endothelial: 2\n",
      "  fetal_quiescent: 3\n",
      "  fetal_replicating: 4\n",
      "  hybrid: 5\n",
      "  microglia: 6\n",
      "  neurons: 7\n",
      "  oligodendrocytes: 8\n",
      "\n",
      "Running get_matrix...\n",
      "\n",
      "NORM-1\n",
      "Selecting top 900 genes by variance...\n",
      "tSNE with exact algorithm is used\n",
      "\n",
      " Pixels: 31 x 31\n",
      "\n",
      "Applying SMOTE...\n",
      "\n",
      "Testing ConvPixel...\n",
      "Image shape: (31, 31)\n",
      "\n",
      "Encoding labels...\n",
      "\n",
      "Converting augmented data to images...\n",
      "\n",
      "Preparing validation images...\n",
      "\n",
      "Finished dataset preparation.\n"
     ]
    }
   ],
   "source": [
    "filepath=\"data/Darmanis.csv\"\n",
    "Process_Vec2Image = Vec2Image_data_processing(filepath=filepath, Parm=Parm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bc5c61",
   "metadata": {},
   "source": [
    "# 2. Vec2Image_model_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c8df07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vec2Image_model_train(Process_Vec2Image):\n",
    "    set_seed(42)\n",
    "    print(\"\\nTraining model...\")\n",
    "    model = get_net_trainer(\n",
    "        Process_Vec2Image['X_train_imgs'],\n",
    "        Process_Vec2Image['y_train_oh'],\n",
    "        Process_Vec2Image['X_val_imgs'],\n",
    "        Process_Vec2Image['y_val_oh'],\n",
    "      \n",
    "    )\n",
    "\n",
    "    Process_Vec2Image['Out'].update({'model': {'net': model}})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68f48912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training model...\n",
      "Epoch 01: Loss=61.0403 | Train Acc=28.10% | Val Acc=17.58%\n",
      "Epoch 02: Loss=50.0994 | Train Acc=59.69% | Val Acc=30.77%\n",
      "Epoch 03: Loss=36.5142 | Train Acc=81.48% | Val Acc=63.74%\n",
      "Epoch 04: Loss=22.2392 | Train Acc=89.32% | Val Acc=78.02%\n",
      "Epoch 05: Loss=12.8240 | Train Acc=96.19% | Val Acc=81.32%\n",
      "Epoch 06: Loss=7.5769 | Train Acc=98.47% | Val Acc=82.42%\n",
      "Epoch 07: Loss=4.9691 | Train Acc=99.24% | Val Acc=83.52%\n",
      "Epoch 08: Loss=3.1429 | Train Acc=99.78% | Val Acc=83.52%\n",
      "Epoch 09: Loss=2.2888 | Train Acc=99.89% | Val Acc=82.42%\n",
      "Epoch 10: Loss=1.5738 | Train Acc=99.89% | Val Acc=84.62%\n",
      "Epoch 11: Loss=1.3090 | Train Acc=100.00% | Val Acc=83.52%\n",
      "Epoch 12: Loss=1.0344 | Train Acc=100.00% | Val Acc=82.42%\n",
      "Epoch 13: Loss=0.8046 | Train Acc=100.00% | Val Acc=80.22%\n",
      "Epoch 14: Loss=0.6982 | Train Acc=100.00% | Val Acc=80.22%\n",
      "Epoch 15: Loss=0.5830 | Train Acc=100.00% | Val Acc=82.42%\n",
      "Epoch 16: Loss=0.5872 | Train Acc=100.00% | Val Acc=81.32%\n",
      "Epoch 17: Loss=0.4709 | Train Acc=100.00% | Val Acc=82.42%\n",
      "Epoch 18: Loss=0.4642 | Train Acc=100.00% | Val Acc=83.52%\n",
      "Epoch 19: Loss=0.3983 | Train Acc=100.00% | Val Acc=83.52%\n",
      "Epoch 20: Loss=0.3672 | Train Acc=100.00% | Val Acc=83.52%\n"
     ]
    }
   ],
   "source": [
    "Vec2Image_model_train(Process_Vec2Image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a3a0a1",
   "metadata": {},
   "source": [
    "# 3. Vec2Image_model_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a406eef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vec2Image_model_test(Out, dset, device='cpu'):\n",
    "    print(\"\\n===== Running model test =====\")\n",
    "    set_seed(42)\n",
    "    # 提取并处理验证集原始数据\n",
    "    X_val_raw = np.nan_to_num(Out['ValidationRawdata'])\n",
    "    gene_idx = Out['selected_gene_idx']\n",
    "    X_val_raw = X_val_raw[gene_idx, :]\n",
    "\n",
    "    dset['Xtest'] = X_val_raw\n",
    "    dset['test_labels'] = Out['ValidationLabelsOrdered']\n",
    "    n_val = dset['Xtest'].shape[1]\n",
    "    dset['test_labels'] = dset['test_labels'][:n_val]\n",
    "\n",
    "    # 执行测试\n",
    "    tester = NetTester(dset, Out, device=device)\n",
    "    acc, XTest_tensor, Y_pred = tester.run_test()\n",
    "\n",
    "    # 输出信息\n",
    "    print(f\"\\nTest accuracy: {acc:.2%}\")\n",
    "    print(\"XP hash:\", hash(tuple(dset['xp'])))\n",
    "    print(\"YP hash:\", hash(tuple(dset['yp'])))\n",
    "    print(\"Test Out XP hash:\", hash(tuple(Out['xp'])))\n",
    "    print(\"First few test labels:\", dset['test_labels'][:5])\n",
    "    print(\"Xtest shape:\", dset['Xtest'].shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc504d1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== Running model test =====\n",
      "\n",
      "Using Norm-1 ...\n",
      "\n",
      "Test accuracy: 83.52%\n",
      "XP hash: 8749714411047054541\n",
      "YP hash: -4047352006026151336\n",
      "Test Out XP hash: 8749714411047054541\n",
      "First few test labels: [0 0 0 1 1]\n",
      "Xtest shape: (900, 91)\n"
     ]
    }
   ],
   "source": [
    "if isinstance(Process_Vec2Image['Out']['model']['net'], tuple):\n",
    "    Process_Vec2Image['Out']['model']['net'] = Process_Vec2Image['Out']['model']['net'][0]\n",
    "Vec2Image_model_test(Process_Vec2Image['Out'], Process_Vec2Image['dset'], device='cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dca6b71",
   "metadata": {},
   "source": [
    "# 4. Vec2Image_features_importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4b98c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vec2Image_features_importance(dest, Out, k, num_classes, device='cpu'):\n",
    "    set_seed(42)\n",
    "    if Out['Norm'] == 1:\n",
    "        print('\\nNORM-1\\n')\n",
    "        Out['Max'] = np.max(dest['Xtest'], axis=1, keepdims=True)\n",
    "        Out['Min'] = np.min(dest['Xtest'], axis=1, keepdims=True)\n",
    "        dest['Xtest'] = (dest['Xtest'] - Out['Min']) / (Out['Max'] - Out['Min'])\n",
    "        dest['Xtest'][np.isnan(dest['Xtest'])] = 0\n",
    "\n",
    "    elif Out['Norm'] == 2:\n",
    "        print('\\nNORM-2\\n')\n",
    "        Out['Min'] = np.min(dest['Xtest'], axis=1, keepdims=True)\n",
    "        dest['Xtest'] = np.log(dest['Xtest'] + np.abs(Out['Min']) + 1)\n",
    "        Out['Max'] = np.max(dest['Xtest'])\n",
    "        dest['Xtest'] = dest['Xtest'] / Out['Max']\n",
    "\n",
    "    countgene = min(dest['Xtest'].shape[0], len(Out['xp']), len(Out['yp']))\n",
    "    error = np.zeros(countgene)\n",
    "\n",
    "    print(f\"\\nCalculating feature importance for {countgene} genes...\")\n",
    "    \n",
    "    for i in range(countgene):\n",
    "        shuffledata = np.copy(dest['Xtest'])\n",
    "        neigh = NearestNeighbors(n_neighbors=k, p=5, metric='minkowski')\n",
    "        neigh.fit(np.column_stack((Out['xp'], Out['yp'])))\n",
    "        mIdx = neigh.kneighbors([[Out['xp'][i], Out['yp'][i]]], return_distance=False)[0]\n",
    "        mIdx = mIdx[mIdx < shuffledata.shape[0]]  \n",
    "        shuffledata[mIdx, :] = 1\n",
    "\n",
    "        num_test_labels = len(dest['test_labels'])\n",
    "        sample_pixel = ConvPixel(shuffledata[:, 0], Out['xp'], Out['yp'], Out['A'], Out['B'], Out['Base'], 0)\n",
    "        height, width = sample_pixel.shape\n",
    "        M = np.zeros((height, width, 1, num_test_labels))\n",
    "\n",
    "        M[:, :, 0, 0] = sample_pixel\n",
    "\n",
    "        for j in range(1, num_test_labels):\n",
    "            M[:, :, 0, j] = ConvPixel(shuffledata[:, j], Out['xp'], Out['yp'], Out['A'], Out['B'], Out['Base'], 0)\n",
    "\n",
    "        # print(M.shape)\n",
    "        X_test_tensor = torch.from_numpy(M).permute(3, 2, 0, 1).float().to(device)\n",
    "\n",
    "        Y_pred = Out['model']['net'](X_test_tensor)\n",
    "        Y_pred = torch.argmax(Y_pred, dim=1).cpu().numpy()\n",
    "\n",
    "        valError = np.mean(Y_pred == dest['test_labels'])\n",
    "\n",
    "\n",
    "        error[i] = valError\n",
    "        # print(f'the running gene number is {i}')\n",
    "\n",
    "    GeneRank = error\n",
    "\n",
    "    top_k_indices = np.argsort(GeneRank)[:num_classes]\n",
    "\n",
    "    top_gene_idx = Out['selected_gene_idx']         \n",
    "    true_gene_idx = top_gene_idx[top_k_indices]\n",
    "    print(f\"Top {num_classes} important genes(original):\", true_gene_idx)\n",
    "    return true_gene_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c54143aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "NORM-1\n",
      "\n",
      "\n",
      "Calculating feature importance for 375 genes...\n",
      "Top 9 important genes(original): [18473 19684  5862  3088 17587  7832  2353 13246 16680]\n"
     ]
    }
   ],
   "source": [
    "true_gene_idx = Vec2Image_features_importance(\n",
    "    Process_Vec2Image['dset'], \n",
    "    Process_Vec2Image['Out'], \n",
    "    k=5, \n",
    "    num_classes=Process_Vec2Image['num_classes'], \n",
    "    device='cpu'\n",
    ")\n",
    "\n",
    "# 存到txt文件\n",
    "output_file = \"Vec2Image_top_genes.txt\"\n",
    "with open(output_file, 'w') as f:\n",
    "    for gene in true_gene_idx:\n",
    "        f.write(f\"{gene}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CXXA1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
